{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Overview\n",
    "\n",
    "This Jupyter Notebook takes in GTFS data and then combines and adjusts the data in order for the MyBus tool.  Run all cells to output these files:\n",
    "\n",
    "* `lines.json` - This file is a list of line numbers to be used in the MyBus tool (to select lines).\n",
    "* `[line-number].json` - A file for each line number that lists unique stops across all trips for that line.\n",
    "\n",
    "As of 5/28/21 data should be output for 141 lines.\n",
    "\n",
    "__TODO: Output files with all matching `stop_id`s for each unique `line` + `stop_name` combination__\n",
    "\n",
    "## Contents\n",
    "\n",
    "[Load GTFS Data](#load-gtfs-data)\n",
    "\n",
    "[Output Lines](#output-lines)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_INPUT_PATH = 'data-input/'\n",
    "DATA_OUTPUT_PATH = 'data-output/'"
   ]
  },
  {
   "source": [
    "<a id=\"load-gtfs-data\"></a>\n",
    "# Load GTFS Data\n",
    "\n",
    "## __`routes.txt`__\n",
    "\n",
    "GTFS files are pulled from: https://gitlab.com/LACMTA/gtfs_bus\n",
    "\n",
    "The data used here is from version hash `9a71d665`.\n",
    "\n",
    "* `route_id`\n",
    "* `route_short_name`\n",
    "\n",
    "## __`stops.txt`__\n",
    "\n",
    "* `stop_id`\n",
    "* `stop_name`\n",
    "* `stop_lat`\n",
    "* `stop_lng`\n",
    "\n",
    "## __`stop_times.txt`__\n",
    "\n",
    "* `trip_id`\n",
    "* `stop_id`\n",
    "* `stop_sequence`\n",
    "* `stop_headsign`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   route_id route_short_name\n",
       "0   2-13139                2\n",
       "1   4-13139                4\n",
       "2  10-13139            10/48\n",
       "3  14-13139            14/37\n",
       "4  16-13139               16\n",
       "5  18-13139               18\n",
       "6  20-13139               20\n",
       "7  28-13139               28\n",
       "8  30-13139               30\n",
       "9  33-13139               33"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>route_id</th>\n      <th>route_short_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2-13139</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4-13139</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10-13139</td>\n      <td>10/48</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14-13139</td>\n      <td>14/37</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16-13139</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>18-13139</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>20-13139</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>28-13139</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>30-13139</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>33-13139</td>\n      <td>33</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "lines = pd.read_csv(DATA_INPUT_PATH + 'routes.txt', \n",
    "    usecols={'route_id', 'route_short_name'},\n",
    "    dtype={'route_id':'string', 'route_short_name':'string'})\n",
    "\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  stop_id                            stop_name   stop_lat    stop_lon\n",
       "0       1                  Paramount / Slauson  33.973248 -118.113113\n",
       "1       3                     Jefferson / 10th  34.025471 -118.328402\n",
       "2       6           120th / Augustus F Hawkins  33.924696 -118.242222\n",
       "3       7  120th / Martin Luther King Hospital  33.924505 -118.240369\n",
       "4      12                    15054 Sherman Way  34.201075 -118.461953"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stop_id</th>\n      <th>stop_name</th>\n      <th>stop_lat</th>\n      <th>stop_lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Paramount / Slauson</td>\n      <td>33.973248</td>\n      <td>-118.113113</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Jefferson / 10th</td>\n      <td>34.025471</td>\n      <td>-118.328402</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>120th / Augustus F Hawkins</td>\n      <td>33.924696</td>\n      <td>-118.242222</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>120th / Martin Luther King Hospital</td>\n      <td>33.924505</td>\n      <td>-118.240369</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12</td>\n      <td>15054 Sherman Way</td>\n      <td>34.201075</td>\n      <td>-118.461953</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "stops = pd.read_csv(DATA_INPUT_PATH + 'stops.txt',\n",
    "    usecols=['stop_id','stop_name','stop_lat','stop_lon'],\n",
    "    dtype={'stop_id':'string','stop_name':'string','stop_lat':'float64','stop_lon':'float64'})\n",
    "stops.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                           trip_id stop_id  stop_sequence  \\\n",
       "0  52088401-DEC20-D02CAR-1_Weekday   10246              1   \n",
       "1  52088401-DEC20-D02CAR-1_Weekday   10248              2   \n",
       "2  52088401-DEC20-D02CAR-1_Weekday    9371              3   \n",
       "3  52088401-DEC20-D02CAR-1_Weekday    9350              4   \n",
       "4  52088401-DEC20-D02CAR-1_Weekday    9351              5   \n",
       "\n",
       "          stop_headsign  \n",
       "0  611 - Vernon Station  \n",
       "1  611 - Vernon Station  \n",
       "2  611 - Vernon Station  \n",
       "3  611 - Vernon Station  \n",
       "4  611 - Vernon Station  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trip_id</th>\n      <th>stop_id</th>\n      <th>stop_sequence</th>\n      <th>stop_headsign</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>10246</td>\n      <td>1</td>\n      <td>611 - Vernon Station</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>10248</td>\n      <td>2</td>\n      <td>611 - Vernon Station</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>9371</td>\n      <td>3</td>\n      <td>611 - Vernon Station</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>9350</td>\n      <td>4</td>\n      <td>611 - Vernon Station</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>9351</td>\n      <td>5</td>\n      <td>611 - Vernon Station</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "stop_times = pd.read_csv(DATA_INPUT_PATH + 'stop_times.txt',\n",
    "    usecols=['trip_id','stop_id','stop_sequence','stop_headsign'],\n",
    "    dtype={'trip_id':'string','stop_id':'string','stop_sequence':'int64','stop_headsign':'string'})\n",
    "stop_times.head(5)"
   ]
  },
  {
   "source": [
    "<a id=\"output-lines\"></a>\n",
    "# Output Lines\n",
    "\n",
    "Output file as: `lines.json`.\n",
    "\n",
    "`.to_json()` method\n",
    "\n",
    "* Only works on a DataFrame\n",
    "* Outputs data by column - use `orient='records'` to output by record\n",
    "\n",
    "Fields in output:\n",
    "\n",
    "* `route_id` - route number plus HASTUS version. For lines with sister routes, will only list first line.\n",
    "  * Ex: `10-13139`\n",
    "* `route_short_name` - route number, includes sister routes.\n",
    "  * Ex: `10/48`\n",
    "\n",
    "Modifications:\n",
    "\n",
    "* The Silver Line and Orange Line do not have `route_short_name` values so those have to be manually added.\n",
    "* The L Line Shuttle and the two Dodger Stadium Express Shuttles will be removed since they're temporary services.\n",
    "* Lines with sister routes may need to be separated to treat each as separate lines.  Unless... a rider can stay on a single vehicle and end up on the other line.  In that case we would want to combine the stops for both lines so they are selectable from the landing page.\n",
    "\n",
    "## MyBus Usage\n",
    "\n",
    "Landing Page - Line Select Dropdown\n",
    "\n",
    "* `route_id` - use as button value, pass this to the results page as a URL parameter\n",
    "* `route_short_name` - user-friendly text for the dropdown (just a number)\n",
    "\n",
    "Results Page - Header\n",
    "\n",
    "* `route_short_name` - use as H1\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     route_id  route_short_name\n",
       "0     2-13139                 2\n",
       "1     4-13139                 4\n",
       "109  10-13139                10\n",
       "111  14-13139                14\n",
       "113  16-13139                16\n",
       "114  16-13139                17\n",
       "2    18-13139                18\n",
       "3    20-13139                20\n",
       "4    28-13139                28\n",
       "5    30-13139                30"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>route_id</th>\n      <th>route_short_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2-13139</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4-13139</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>10-13139</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>111</th>\n      <td>14-13139</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>16-13139</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>16-13139</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18-13139</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20-13139</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28-13139</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>30-13139</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Add route_short_name values for the 901 (Orange Line) and 910/950 (Silver Line)\n",
    "lines.loc[lines[\"route_id\"] == '910-13139', 'route_short_name'] = '910/950'\n",
    "lines.loc[lines[\"route_id\"] == '901-13139', 'route_short_name'] = '901'\n",
    "\n",
    "# Line 16/17 is listed as only '16' in the GTFS data even though headsigns show 17.\n",
    "# Add line 17 back in.\n",
    "lines.loc[lines[\"route_id\"] == '16-13139', 'route_short_name'] = '16/17'\n",
    "\n",
    "# Add back in lines: 177, 244, 489, 788.\n",
    "lines.loc[len(lines.index)] = ['177', '177'] # no stops\n",
    "lines.loc[len(lines.index)] = ['244', '244'] # has stops\n",
    "lines.loc[len(lines.index)] = ['489', '489'] # has stops\n",
    "lines.loc[len(lines.index)] = ['788', '788'] # no stops\n",
    "\n",
    "# Remove the entries for the Dodger Express and L Line (Gold) Shuttle\n",
    "lines = lines.loc[~lines[\"route_id\"].isin(['DSE-HG'])]\n",
    "lines = lines.loc[~lines[\"route_id\"].isin(['DSE-US'])]\n",
    "lines = lines.loc[~lines[\"route_id\"].isin(['854-13139'])]\n",
    "\n",
    "# Separate out the sister lines.\n",
    "lines_separated = lines.loc[lines['route_short_name'].str.contains('/'), 'route_short_name'].values\n",
    "\n",
    "for i, l in enumerate(lines_separated):\n",
    "    id = lines.loc[lines['route_short_name'] == l]['route_id'].values[0]\n",
    "    slash = l.find('/')\n",
    "    line1 = l[:slash]\n",
    "    line2 = l[slash+1:]\n",
    "    \n",
    "    lines = lines.loc[~lines[\"route_id\"].isin([id])]\n",
    "    newlines = pd.DataFrame([[id, line1], [id, line2]], columns=['route_id', 'route_short_name'])\n",
    "    lines = lines.append(newlines, ignore_index=True)\n",
    "\n",
    "# cast route_short_name to int32 so that we can sort by their integer value\n",
    "lines = lines.astype({'route_short_name': 'int32'}).sort_values('route_short_name')\n",
    "lines.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  2   4  10  14  16  17  18  20  28  30  33  35  37  38  40  45  48  51\n  52  53  55  60  62  66  68  70  71  76  78  79  81  83  90  91  92  94\n  96 102 105 106 108 110 111 115 117 120 125 127 128 130 150 152 154 155\n 158 161 162 163 164 165 166 167 169 175 176 177 180 181 183 200 201 202\n 204 205 206 207 209 210 211 212 215 217 218 222 224 230 232 233 234 236\n 237 239 240 242 243 244 245 246 251 252 256 258 260 264 265 266 267 268\n 344 460 487 489 501 534 550 577 601 602 603 605 611 656 665 685 686 687\n 704 720 733 734 744 750 754 757 770 780 788 794 901 910 950]\n141\n"
     ]
    }
   ],
   "source": [
    "# Create an array of all valid lines \n",
    "# Use this to iterate through all lines listed on MyBus\n",
    "# As of 5/30/21, this is 141 lines.\n",
    "lines_array = lines.loc[:, 'route_short_name'].values\n",
    "print(lines_array)\n",
    "print(len(lines_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     lines\n",
       "0        2\n",
       "1        4\n",
       "2       10\n",
       "3       14\n",
       "4       16\n",
       "..     ...\n",
       "136    788\n",
       "137    794\n",
       "138    901\n",
       "139    910\n",
       "140    950\n",
       "\n",
       "[141 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lines</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>136</th>\n      <td>788</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>794</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>901</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>910</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>950</td>\n    </tr>\n  </tbody>\n</table>\n<p>141 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# create a dataframe of this array:\n",
    "df_lines_array = pd.DataFrame(lines_array, columns=['lines'])\n",
    "df_lines_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0        2\n1        4\n109     10\n111     14\n113     16\n114     17\n2       18\n3       20\n4       28\n5       30\n6       33\n115     35\n112     37\n116     38\n7       40\n8       45\n110     48\n117     51\n118     52\n9       53\n10      55\n11      60\n12      62\n13      66\n14      68\n15      70\n16      71\n17      76\n119     78\n120     79\n18      81\n19      83\n121     90\n122     91\n20      92\n21      94\n22      96\n23     102\n24     105\n25     106\n26     108\n27     110\n28     111\n29     115\n30     117\n31     120\n32     125\n33     127\n34     128\n35     130\n123    150\n36     152\n37     154\n38     155\n39     158\n40     161\n125    162\n126    163\n41     164\n42     165\n43     166\n44     167\n45     169\n46     175\n47     176\n105    177\n127    180\n128    181\n48     183\n49     200\n50     201\n51     202\n52     204\n53     205\n54     206\n55     207\n56     209\n57     210\n129    211\n58     212\n130    215\n59     217\n60     218\n61     222\n62     224\n63     230\n64     232\n65     233\n66     234\n67     236\n131    237\n68     239\n124    240\n133    242\n134    243\n106    244\n69     245\n70     246\n71     251\n72     252\n73     256\n74     258\n75     260\n135    264\n76     265\n77     266\n136    267\n78     268\n79     344\n80     460\n81     487\n107    489\n82     501\n83     534\n84     550\n85     577\n86     601\n87     602\n88     603\n89     605\n90     611\n132    656\n91     665\n92     685\n137    686\n138    687\n93     704\n94     720\n95     733\n96     734\n97     744\n98     750\n99     754\n100    757\n101    770\n102    780\n108    788\n103    794\n104    901\n139    910\n140    950\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# OUTPUT lines.json\n",
    "######################################################\n",
    "lines.to_json(DATA_OUTPUT_PATH + \"lines.json\",orient='records')\n",
    "\n",
    "# if we remove \"-13139\" from route_id it will be identical to route_short_name\n",
    "#lines.route_id = lines.route_id.str.replace('-13139','')"
   ]
  },
  {
   "source": [
    "# Combine Lines & Stops Data\n",
    "\n",
    "Merge `stop_times` and `stops` using a LEFT JOIN on `stop_id`.  For each stop on a line, this will show that stop's name and lat/lng.\n",
    "\n",
    "Use the `lines_and_stops` dataframe to generate a file for each line that lists all unique stops for that line."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                           trip_id stop_id  stop_sequence  \\\n",
       "0  52088401-DEC20-D02CAR-1_Weekday   10246              1   \n",
       "1  52088401-DEC20-D02CAR-1_Weekday   10248              2   \n",
       "2  52088401-DEC20-D02CAR-1_Weekday    9371              3   \n",
       "3  52088401-DEC20-D02CAR-1_Weekday    9350              4   \n",
       "4  52088401-DEC20-D02CAR-1_Weekday    9351              5   \n",
       "\n",
       "          stop_headsign            stop_name   stop_lat    stop_lon  \n",
       "0  611 - Vernon Station  Vernon / Long Beach  34.004050 -118.242837  \n",
       "1  611 - Vernon Station      Vernon / Morgan  34.004040 -118.244926  \n",
       "2  611 - Vernon Station     Compton / Vernon  34.003630 -118.247907  \n",
       "3  611 - Vernon Station       Compton / 46th  34.001767 -118.247915  \n",
       "4  611 - Vernon Station       Compton / 48th  33.999487 -118.247918  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trip_id</th>\n      <th>stop_id</th>\n      <th>stop_sequence</th>\n      <th>stop_headsign</th>\n      <th>stop_name</th>\n      <th>stop_lat</th>\n      <th>stop_lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>10246</td>\n      <td>1</td>\n      <td>611 - Vernon Station</td>\n      <td>Vernon / Long Beach</td>\n      <td>34.004050</td>\n      <td>-118.242837</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>10248</td>\n      <td>2</td>\n      <td>611 - Vernon Station</td>\n      <td>Vernon / Morgan</td>\n      <td>34.004040</td>\n      <td>-118.244926</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>9371</td>\n      <td>3</td>\n      <td>611 - Vernon Station</td>\n      <td>Compton / Vernon</td>\n      <td>34.003630</td>\n      <td>-118.247907</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>9350</td>\n      <td>4</td>\n      <td>611 - Vernon Station</td>\n      <td>Compton / 46th</td>\n      <td>34.001767</td>\n      <td>-118.247915</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>9351</td>\n      <td>5</td>\n      <td>611 - Vernon Station</td>\n      <td>Compton / 48th</td>\n      <td>33.999487</td>\n      <td>-118.247918</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "lines_and_stops = pd.merge(stop_times, stops, how=\"left\", on=\"stop_id\")\n",
    "lines_and_stops.head(5)\n",
    "\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^48\\s', regex=True)]\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^794\\s', regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10 lines processed\n",
      "20 lines processed\n",
      "30 lines processed\n",
      "40 lines processed\n",
      "50 lines processed\n",
      "60 lines processed\n",
      "70 lines processed\n",
      "80 lines processed\n",
      "90 lines processed\n",
      "100 lines processed\n",
      "110 lines processed\n",
      "120 lines processed\n",
      "130 lines processed\n",
      "140 lines processed\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  stop_id         stop_headsign            stop_name   line\n",
       "0   10246  611 - Vernon Station  Vernon / Long Beach  611.0\n",
       "1   10248  611 - Vernon Station      Vernon / Morgan  611.0\n",
       "2    9371  611 - Vernon Station     Compton / Vernon  611.0\n",
       "3    9350  611 - Vernon Station       Compton / 46th  611.0\n",
       "4    9351  611 - Vernon Station       Compton / 48th  611.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stop_id</th>\n      <th>stop_headsign</th>\n      <th>stop_name</th>\n      <th>line</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10246</td>\n      <td>611 - Vernon Station</td>\n      <td>Vernon / Long Beach</td>\n      <td>611.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10248</td>\n      <td>611 - Vernon Station</td>\n      <td>Vernon / Morgan</td>\n      <td>611.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9371</td>\n      <td>611 - Vernon Station</td>\n      <td>Compton / Vernon</td>\n      <td>611.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9350</td>\n      <td>611 - Vernon Station</td>\n      <td>Compton / 46th</td>\n      <td>611.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9351</td>\n      <td>611 - Vernon Station</td>\n      <td>Compton / 48th</td>\n      <td>611.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Create a simplified version of the lines_and_stops dataframe\n",
    "# Replace the stop_headsign column with the line number extracted into a 'line' column\n",
    "\n",
    "simple_lines_stops = lines_and_stops[['stop_id','stop_headsign','stop_name']].copy()\n",
    "simple_lines_stops['line'] = np.nan\n",
    "counter = 1\n",
    "\n",
    "for line in lines_array:\n",
    "    line_regex = '^' + str(line) + '\\s'\n",
    "    simple_lines_stops.loc[simple_lines_stops['stop_headsign'].str.contains(line_regex), 'line'] = line\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 10 == 0:\n",
    "        print(str(counter) + ' lines processed')\n",
    "\n",
    "simple_lines_stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        stop_id                         stop_name  line\n",
       "0         10246               Vernon / Long Beach   611\n",
       "1         10248                   Vernon / Morgan   611\n",
       "2          9371                  Compton / Vernon   611\n",
       "3          9350                    Compton / 46th   611\n",
       "4          9351                    Compton / 48th   611\n",
       "...         ...                               ...   ...\n",
       "1790800   13422             Figueroa / Exposition   200\n",
       "1790801   13424                  Figueroa / State   200\n",
       "1790802   13437                   Figueroa / 39th   200\n",
       "1790803    2738  Martin Luther King Jr / Figueroa   200\n",
       "1790804    2459      Hill / Martin Luther King Jr   200\n",
       "\n",
       "[1751099 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stop_id</th>\n      <th>stop_name</th>\n      <th>line</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10246</td>\n      <td>Vernon / Long Beach</td>\n      <td>611</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10248</td>\n      <td>Vernon / Morgan</td>\n      <td>611</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9371</td>\n      <td>Compton / Vernon</td>\n      <td>611</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9350</td>\n      <td>Compton / 46th</td>\n      <td>611</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9351</td>\n      <td>Compton / 48th</td>\n      <td>611</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1790800</th>\n      <td>13422</td>\n      <td>Figueroa / Exposition</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>1790801</th>\n      <td>13424</td>\n      <td>Figueroa / State</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>1790802</th>\n      <td>13437</td>\n      <td>Figueroa / 39th</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>1790803</th>\n      <td>2738</td>\n      <td>Martin Luther King Jr / Figueroa</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>1790804</th>\n      <td>2459</td>\n      <td>Hill / Martin Luther King Jr</td>\n      <td>200</td>\n    </tr>\n  </tbody>\n</table>\n<p>1751099 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "simple_lines_stops.replace('', float(\"NaN\"), inplace=True)\n",
    "simple_lines_stops.dropna(subset = ['line'], inplace=True)\n",
    "simple_lines_stops.line = simple_lines_stops.line.astype('int')\n",
    "\n",
    "# stop data for 139 lines (lines 177 and 788 are not in the GTFS)\n",
    "simple_lines_stops = simple_lines_stops[['stop_id','stop_name','line']].copy()\n",
    "\n",
    "simple_lines_stops\n",
    "\n",
    "# simple_lines_stops\n",
    "# dtypes____________\n",
    "# stop_id   string\n",
    "# line      int"
   ]
  },
  {
   "source": [
    "# Looking at Stops Data\n",
    "\n",
    "Questions:\n",
    "\n",
    "* How many records are there in `lines_and_stops` for a particular line?\n",
    "  * Use REGEX matching on `stop_headsign`. Will need to use an OR operator for sisters lines because each has distinct headsign values.\n",
    "* Of those records, how many unique `trip_id`s are there?\n",
    "* Of those records, how many unique `stop_name`s are there?\n",
    "* What is the highest `stop_sequence` value for that line?\n",
    "\n",
    "## Stops Data Findings\n",
    "\n",
    "Line 2\n",
    "\n",
    "* 31,094 stop times along Line 2\n",
    "* 377 unique trips\n",
    "* 92 stops MAX within a single trip\n",
    "* 377 x 92 = 34,684 - this means there are some trips with fewer than 92 stops\n",
    "* 123 unique stop names - this means trips do not all contain the same set of stops\n",
    "\n",
    "Line 10/48\n",
    "\n",
    "* ??\n",
    "\n",
    "Highest `stop_sequence`\n",
    "\n",
    "* Line 90\n",
    "* 136 is the highest value\n",
    "* Line 90 has 158 total unique stops."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################\n",
    "#  Line 2          #\n",
    "####################\n",
    "\n",
    "# All values for Line 2 = 31,094\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^2\\s', regex=True)]\n",
    " \n",
    "# Unique stop names for Line 2 = 123\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^2\\s', regex=True)].stop_name.unique()\n",
    "\n",
    "# Unique trip_ids for Line 2 = 377\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^2\\s', regex=True)].trip_id.unique()\n",
    "\n",
    "# Line 2 stops sorted by highest stop_sequence value = 92\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^2\\s', regex=True)].sort_values('stop_sequence', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "#  Lines 10/48     #\n",
    "####################\n",
    "\n",
    "# REGEX: ^(10\\s|48\\s)\n",
    "\n",
    "# All values for Line 10 = 12,534 rows\n",
    "# All values for Line 10/48 = 16,524 rows\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^10\\s', regex=True)]\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^(10\\s|48\\s)', regex=True)]\n",
    "\n",
    "# Unique trip_ids for Line 10 = 231\n",
    "# Unique trip_ids for Line 10/48 = 316\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^10\\s', regex=True)].trip_id.unique()\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^(10\\s|48\\s)', regex=True)].trip_id.unique()\n",
    "\n",
    "# Unique stop names for Line 10 = 117\n",
    "# Unique stop names for Line 10/48 = 132\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^10\\s', regex=True)].stop_name.unique()\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^(10\\s|48\\s)', regex=True)].stop_name.unique()\n",
    "\n",
    "# Line 10/48 stops sorted by highest stop_sequence value = 102\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^(10\\s|48\\s)', regex=True)].sort_values('stop_sequence', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line 90 has highest stop_sequence value of 136\n",
    "#lines_and_stops.sort_values('stop_sequence', ascending=False).head(10)\n",
    "\n",
    "# Line 90 has 158 unique stop names\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^90\\s', regex=True)].stop_name.unique()"
   ]
  },
  {
   "source": [
    "# Output All Stops For Each Line\n",
    "\n",
    "Use `.drop_duplicates()` to generate a new dataframe with only unique values.  Using `.[column name].unique()` outputs a StringArray and we need a DataFrame in order to call `.to_json()`.\n",
    "\n",
    "Sort results by `stop_name` because we're combining multiple trips that may each have their own set of stops along their routes.\n",
    "\n",
    "Fields in output:\n",
    "\n",
    "* `stop_id`\n",
    "* `stop_name`\n",
    "\n",
    "## Usage\n",
    "\n",
    "Landing Page - Stop Select Dropdowns\n",
    "\n",
    "* `stop_id` - use as button value, pass this to the results page as a URL parameter\n",
    "* `stop_name` - user-friendly text for the dropdown\n",
    "\n",
    "## Method\n",
    "\n",
    "Loop through data to generate a separate file for each line.  Each file will contain all unique `stop_name`s for that line.  Lines are matched using the `stop_headsign` field.  Only one line number shows up at a time in the `stop_headsign`.\n",
    "\n",
    "* Create an array of all the `route_short_name` values which should match the line numbers within `stop_headsign`.\n",
    "* For each of those line numbers, find the rows in `lines_and_stops` that contain that line number within `stop_headsign`.\n",
    "* From those values, drop duplicate `stop_name`s to create a list of all unique stops for that line.\n",
    "* Sort the values so the `stop_name`s are in alphabetical order and output the results to JSON files.\n",
    "\n",
    "## Note\n",
    "\n",
    "The initial version of the generated data only took the first instance of `stop_name` (using `drop_duplicates`).  However, the following factors make it so that all `stop_id`s for a `stop_name` should be included in the data:\n",
    "\n",
    "* There can be multiple `stop_id`s that match a single `stop_name`.\n",
    "* The selection dropdown on MyBus uses `stop_name` and we don't offer a way to differentiate between `stop_id`s.\n",
    "* The stop_changes data does not include `stop_name`s that match the GTFS data, mostly just `stop_id`.\n",
    "\n",
    "## TODO\n",
    "\n",
    "* Check `stop_name`s for any abbreviations that should be corrected."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "141 lines\n",
      "[  2   4  10  14  16  17  18  20  28  30  33  35  37  38  40  45  48  51\n",
      "  52  53  55  60  62  66  68  70  71  76  78  79  81  83  90  91  92  94\n",
      "  96 102 105 106 108 110 111 115 117 120 125 127 128 130 150 152 154 155\n",
      " 158 161 162 163 164 165 166 167 169 175 176 177 180 181 183 200 201 202\n",
      " 204 205 206 207 209 210 211 212 215 217 218 222 224 230 232 233 234 236\n",
      " 237 239 240 242 243 244 245 246 251 252 256 258 260 264 265 266 267 268\n",
      " 344 460 487 489 501 534 550 577 601 602 603 605 611 656 665 685 686 687\n",
      " 704 720 733 734 744 750 754 757 770 780 788 794 901 910 950]\n",
      "Line data-output/stops/2.json created\n",
      "Line data-output/stops/4.json created\n",
      "Line data-output/stops/10.json created\n",
      "Line data-output/stops/14.json created\n",
      "Line data-output/stops/16.json created\n",
      "Line data-output/stops/17.json created\n",
      "Line data-output/stops/18.json created\n",
      "Line data-output/stops/20.json created\n",
      "Line data-output/stops/28.json created\n",
      "Line data-output/stops/30.json created\n",
      "Line data-output/stops/33.json created\n",
      "Line data-output/stops/35.json created\n",
      "Line data-output/stops/37.json created\n",
      "Line data-output/stops/38.json created\n",
      "Line data-output/stops/40.json created\n",
      "Line data-output/stops/45.json created\n",
      "Line data-output/stops/48.json created\n",
      "Line data-output/stops/51.json created\n",
      "Line data-output/stops/52.json created\n",
      "Line data-output/stops/53.json created\n",
      "Line data-output/stops/55.json created\n",
      "Line data-output/stops/60.json created\n",
      "Line data-output/stops/62.json created\n",
      "Line data-output/stops/66.json created\n",
      "Line data-output/stops/68.json created\n",
      "Line data-output/stops/70.json created\n",
      "Line data-output/stops/71.json created\n",
      "Line data-output/stops/76.json created\n",
      "Line data-output/stops/78.json created\n",
      "Line data-output/stops/79.json created\n",
      "Line data-output/stops/81.json created\n",
      "Line data-output/stops/83.json created\n",
      "Line data-output/stops/90.json created\n",
      "Line data-output/stops/91.json created\n",
      "Line data-output/stops/92.json created\n",
      "Line data-output/stops/94.json created\n",
      "Line data-output/stops/96.json created\n",
      "Line data-output/stops/102.json created\n",
      "Line data-output/stops/105.json created\n",
      "Line data-output/stops/106.json created\n",
      "Line data-output/stops/108.json created\n",
      "Line data-output/stops/110.json created\n",
      "Line data-output/stops/111.json created\n",
      "Line data-output/stops/115.json created\n",
      "Line data-output/stops/117.json created\n",
      "Line data-output/stops/120.json created\n",
      "Line data-output/stops/125.json created\n",
      "Line data-output/stops/127.json created\n",
      "Line data-output/stops/128.json created\n",
      "Line data-output/stops/130.json created\n",
      "Line data-output/stops/150.json created\n",
      "Line data-output/stops/152.json created\n",
      "Line data-output/stops/154.json created\n",
      "Line data-output/stops/155.json created\n",
      "Line data-output/stops/158.json created\n",
      "Line data-output/stops/161.json created\n",
      "Line data-output/stops/162.json created\n",
      "Line data-output/stops/163.json created\n",
      "Line data-output/stops/164.json created\n",
      "Line data-output/stops/165.json created\n",
      "Line data-output/stops/166.json created\n",
      "Line data-output/stops/167.json created\n",
      "Line data-output/stops/169.json created\n",
      "Line data-output/stops/175.json created\n",
      "Line data-output/stops/176.json created\n",
      "Line data-output/stops/177.json created\n",
      "Line data-output/stops/180.json created\n",
      "Line data-output/stops/181.json created\n",
      "Line data-output/stops/183.json created\n",
      "Line data-output/stops/200.json created\n",
      "Line data-output/stops/201.json created\n",
      "Line data-output/stops/202.json created\n",
      "Line data-output/stops/204.json created\n",
      "Line data-output/stops/205.json created\n",
      "Line data-output/stops/206.json created\n",
      "Line data-output/stops/207.json created\n",
      "Line data-output/stops/209.json created\n",
      "Line data-output/stops/210.json created\n",
      "Line data-output/stops/211.json created\n",
      "Line data-output/stops/212.json created\n",
      "Line data-output/stops/215.json created\n",
      "Line data-output/stops/217.json created\n",
      "Line data-output/stops/218.json created\n",
      "Line data-output/stops/222.json created\n",
      "Line data-output/stops/224.json created\n",
      "Line data-output/stops/230.json created\n",
      "Line data-output/stops/232.json created\n",
      "Line data-output/stops/233.json created\n",
      "Line data-output/stops/234.json created\n",
      "Line data-output/stops/236.json created\n",
      "Line data-output/stops/237.json created\n",
      "Line data-output/stops/239.json created\n",
      "Line data-output/stops/240.json created\n",
      "Line data-output/stops/242.json created\n",
      "Line data-output/stops/243.json created\n",
      "Line data-output/stops/244.json created\n",
      "Line data-output/stops/245.json created\n",
      "Line data-output/stops/246.json created\n",
      "Line data-output/stops/251.json created\n",
      "Line data-output/stops/252.json created\n",
      "Line data-output/stops/256.json created\n",
      "Line data-output/stops/258.json created\n",
      "Line data-output/stops/260.json created\n",
      "Line data-output/stops/264.json created\n",
      "Line data-output/stops/265.json created\n",
      "Line data-output/stops/266.json created\n",
      "Line data-output/stops/267.json created\n",
      "Line data-output/stops/268.json created\n",
      "Line data-output/stops/344.json created\n",
      "Line data-output/stops/460.json created\n",
      "Line data-output/stops/487.json created\n",
      "Line data-output/stops/489.json created\n",
      "Line data-output/stops/501.json created\n",
      "Line data-output/stops/534.json created\n",
      "Line data-output/stops/550.json created\n",
      "Line data-output/stops/577.json created\n",
      "Line data-output/stops/601.json created\n",
      "Line data-output/stops/602.json created\n",
      "Line data-output/stops/603.json created\n",
      "Line data-output/stops/605.json created\n",
      "Line data-output/stops/611.json created\n",
      "Line data-output/stops/656.json created\n",
      "Line data-output/stops/665.json created\n",
      "Line data-output/stops/685.json created\n",
      "Line data-output/stops/686.json created\n",
      "Line data-output/stops/687.json created\n",
      "Line data-output/stops/704.json created\n",
      "Line data-output/stops/720.json created\n",
      "Line data-output/stops/733.json created\n",
      "Line data-output/stops/734.json created\n",
      "Line data-output/stops/744.json created\n",
      "Line data-output/stops/750.json created\n",
      "Line data-output/stops/754.json created\n",
      "Line data-output/stops/757.json created\n",
      "Line data-output/stops/770.json created\n",
      "Line data-output/stops/780.json created\n",
      "Line data-output/stops/788.json created\n",
      "Line data-output/stops/794.json created\n",
      "Line data-output/stops/901.json created\n",
      "Line data-output/stops/910.json created\n",
      "Line data-output/stops/950.json created\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# OUTPUT all stops as *line*.json\n",
    "# Drops duplicates based on stop_name\n",
    "######################################################\n",
    "\n",
    "line_regex = ''\n",
    "\n",
    "for line in lines_array:\n",
    "    line_regex = '^' + str(line) + '\\s'\n",
    "    line_filename = DATA_OUTPUT_PATH + 'stops/' + str(line) + '.json'\n",
    "\n",
    "    dedupped_stops = lines_and_stops[lines_and_stops['stop_headsign'].str.contains(line_regex, regex=True)].drop_duplicates(subset='stop_name')\n",
    "    dedupped_stops[['stop_id','stop_name']].sort_values('stop_name').to_json(line_filename, orient='records')\n",
    "\n",
    "    print('Line ' + line_filename + ' created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "139\n[2, 4, 10, 14, 16, 17, 18, 20, 28, 30, 33, 35, 37, 38, 40, 45, 48, 51, 52, 53, 55, 60, 62, 66, 68, 70, 71, 76, 78, 79, 81, 83, 90, 91, 92, 94, 96, 102, 105, 106, 108, 110, 111, 115, 117, 120, 125, 127, 128, 130, 150, 152, 154, 155, 158, 161, 162, 163, 164, 165, 166, 167, 169, 175, 176, 180, 181, 183, 200, 201, 202, 204, 205, 206, 207, 209, 210, 211, 212, 215, 217, 218, 222, 224, 230, 232, 233, 234, 236, 237, 239, 240, 242, 243, 244, 245, 246, 251, 252, 256, 258, 260, 264, 265, 266, 267, 268, 344, 460, 487, 489, 501, 534, 550, 577, 601, 602, 603, 605, 611, 656, 665, 685, 686, 687, 704, 720, 733, 734, 744, 750, 754, 757, 770, 780, 794, 901, 910, 950]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     lines  index     _merge\n",
       "65     177    NaN  left_only\n",
       "136    788    NaN  left_only"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lines</th>\n      <th>index</th>\n      <th>_merge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>65</th>\n      <td>177</td>\n      <td>NaN</td>\n      <td>left_only</td>\n    </tr>\n    <tr>\n      <th>136</th>\n      <td>788</td>\n      <td>NaN</td>\n      <td>left_only</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "headsign_lines = simple_lines_stops.line.unique()\n",
    "print(len(headsign_lines))\n",
    "print(sorted(headsign_lines))\n",
    "\n",
    "df_headsign_lines = pd.DataFrame(headsign_lines, columns=['lines']).sort_values(by=['lines']).reset_index()\n",
    "\n",
    "# LEFT = routes.txt but modified\n",
    "# RIGHT = stop_headsigns\n",
    "lines_merged = pd.merge(df_lines_array, df_headsign_lines, how='left', indicator=True)\n",
    "lines_merged[lines_merged._merge != 'both']\n",
    "\n",
    "# 177 and 788 both are not in the GTFS and don't have stops\n",
    "# that's why they aren't in the stop_headsigns column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       line                           stop_name stop_id_agg\n",
       "0         2                  Alvarado / Montana        3360\n",
       "1         2                   Alvarado / Sunset        3362\n",
       "2         2                     Broadway / 12th       15598\n",
       "3         2                      Broadway / 1st        4767\n",
       "4         2                      Broadway / 3rd       13227\n",
       "...     ...                                 ...         ...\n",
       "10894   950                       Pacific / 7th   5410|5411\n",
       "10895   950            Spring / 1st - City Hall       11917\n",
       "10896   950                     Spring / Temple       12416\n",
       "10897   950      USC Medical Ctr Busway Station  15029|5048\n",
       "10898   950  Union Station Patsaouras Bus Plaza   3300|3301\n",
       "\n",
       "[10899 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>line</th>\n      <th>stop_name</th>\n      <th>stop_id_agg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Alvarado / Montana</td>\n      <td>3360</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Alvarado / Sunset</td>\n      <td>3362</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Broadway / 12th</td>\n      <td>15598</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>Broadway / 1st</td>\n      <td>4767</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>Broadway / 3rd</td>\n      <td>13227</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10894</th>\n      <td>950</td>\n      <td>Pacific / 7th</td>\n      <td>5410|5411</td>\n    </tr>\n    <tr>\n      <th>10895</th>\n      <td>950</td>\n      <td>Spring / 1st - City Hall</td>\n      <td>11917</td>\n    </tr>\n    <tr>\n      <th>10896</th>\n      <td>950</td>\n      <td>Spring / Temple</td>\n      <td>12416</td>\n    </tr>\n    <tr>\n      <th>10897</th>\n      <td>950</td>\n      <td>USC Medical Ctr Busway Station</td>\n      <td>15029|5048</td>\n    </tr>\n    <tr>\n      <th>10898</th>\n      <td>950</td>\n      <td>Union Station Patsaouras Bus Plaza</td>\n      <td>3300|3301</td>\n    </tr>\n  </tbody>\n</table>\n<p>10899 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "######################################################\n",
    "# OUTPUT all stops as *line*.json\n",
    "# Output files with all matching `stop_id`s for each unique `line` + `stop_name` combination\n",
    "######################################################\n",
    "\n",
    "# Group line+stop data by unique line + stop combinations\n",
    "# Create a new column that aggregates the unique associated stop_ids\n",
    "grouped_stops = simple_lines_stops.groupby(['line', 'stop_name'])\n",
    "unique_grouped_stops = grouped_stops['stop_id'].unique()\n",
    "\n",
    "unique_grouped_stops = unique_grouped_stops.reset_index()\n",
    "\n",
    "unique_grouped_stops['stop_id_agg'] = ''\n",
    "\n",
    "def aggregate_stop_id(row):\n",
    "    count = 0\n",
    "    result = ''\n",
    "    for id in row.stop_id:\n",
    "        if count > 0:\n",
    "            result += '|'\n",
    "        result += id\n",
    "        count += 1\n",
    "    return result\n",
    "\n",
    "unique_grouped_stops.stop_id_agg = unique_grouped_stops.apply(aggregate_stop_id, axis=1)\n",
    "\n",
    "aggregated_grouped_stops = unique_grouped_stops[['line','stop_name','stop_id_agg']].copy()\n",
    "\n",
    "aggregated_grouped_stops\n",
    "\n",
    "# unique_grouped_stops.to_json(DATA_OUTPUT_PATH + 'unique-grouped-stops.json', orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       line                           stop_name stop_id_agg\n",
       "0         2                  Alvarado / Montana        3360\n",
       "1         2                   Alvarado / Sunset        3362\n",
       "2         2                     Broadway / 12th       15598\n",
       "3         2                      Broadway / 1st        4767\n",
       "4         2                      Broadway / 3rd       13227\n",
       "...     ...                                 ...         ...\n",
       "10894   950                       Pacific / 7th   5410|5411\n",
       "10895   950            Spring / 1st - City Hall       11917\n",
       "10896   950                     Spring / Temple       12416\n",
       "10897   950      USC Medical Ctr Busway Station  15029|5048\n",
       "10898   950  Union Station Patsaouras Bus Plaza   3300|3301\n",
       "\n",
       "[10899 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>line</th>\n      <th>stop_name</th>\n      <th>stop_id_agg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Alvarado / Montana</td>\n      <td>3360</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Alvarado / Sunset</td>\n      <td>3362</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Broadway / 12th</td>\n      <td>15598</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>Broadway / 1st</td>\n      <td>4767</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>Broadway / 3rd</td>\n      <td>13227</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10894</th>\n      <td>950</td>\n      <td>Pacific / 7th</td>\n      <td>5410|5411</td>\n    </tr>\n    <tr>\n      <th>10895</th>\n      <td>950</td>\n      <td>Spring / 1st - City Hall</td>\n      <td>11917</td>\n    </tr>\n    <tr>\n      <th>10896</th>\n      <td>950</td>\n      <td>Spring / Temple</td>\n      <td>12416</td>\n    </tr>\n    <tr>\n      <th>10897</th>\n      <td>950</td>\n      <td>USC Medical Ctr Busway Station</td>\n      <td>15029|5048</td>\n    </tr>\n    <tr>\n      <th>10898</th>\n      <td>950</td>\n      <td>Union Station Patsaouras Bus Plaza</td>\n      <td>3300|3301</td>\n    </tr>\n  </tbody>\n</table>\n<p>10899 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 372
    }
   ],
   "source": [
    "# unique_agg_stops = aggregated_grouped_stops.drop_duplicates(subset = ['line','stop_id_agg'])\n",
    "# unique_agg_stops\n",
    "# no difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Line data-output/stops-agg/2.json created (123)\n",
      "Line data-output/stops-agg/4.json created (129)\n",
      "Line data-output/stops-agg/10.json created (117)\n",
      "Line data-output/stops-agg/14.json created (47)\n",
      "Line data-output/stops-agg/16.json created (80)\n",
      "Line data-output/stops-agg/17.json created (84)\n",
      "Line data-output/stops-agg/18.json created (94)\n",
      "Line data-output/stops-agg/20.json created (103)\n",
      "Line data-output/stops-agg/28.json created (124)\n",
      "Line data-output/stops-agg/30.json created (90)\n",
      "Line data-output/stops-agg/33.json created (115)\n",
      "Line data-output/stops-agg/35.json created (55)\n",
      "Line data-output/stops-agg/37.json created (31)\n",
      "Line data-output/stops-agg/38.json created (54)\n",
      "Line data-output/stops-agg/40.json created (125)\n",
      "Line data-output/stops-agg/45.json created (88)\n",
      "Line data-output/stops-agg/48.json created (49)\n",
      "Line data-output/stops-agg/51.json created (108)\n",
      "Line data-output/stops-agg/52.json created (105)\n",
      "Line data-output/stops-agg/53.json created (106)\n",
      "Line data-output/stops-agg/55.json created (89)\n",
      "Line data-output/stops-agg/60.json created (120)\n",
      "Line data-output/stops-agg/62.json created (101)\n",
      "Line data-output/stops-agg/66.json created (85)\n",
      "Line data-output/stops-agg/68.json created (67)\n",
      "Line data-output/stops-agg/70.json created (107)\n",
      "Line data-output/stops-agg/71.json created (61)\n",
      "Line data-output/stops-agg/76.json created (89)\n",
      "Line data-output/stops-agg/78.json created (125)\n",
      "Line data-output/stops-agg/79.json created (103)\n",
      "Line data-output/stops-agg/81.json created (113)\n",
      "Line data-output/stops-agg/83.json created (85)\n",
      "Line data-output/stops-agg/90.json created (158)\n",
      "Line data-output/stops-agg/91.json created (118)\n",
      "Line data-output/stops-agg/92.json created (152)\n",
      "Line data-output/stops-agg/94.json created (121)\n",
      "Line data-output/stops-agg/96.json created (78)\n",
      "Line data-output/stops-agg/102.json created (122)\n",
      "Line data-output/stops-agg/105.json created (82)\n",
      "Line data-output/stops-agg/106.json created (46)\n",
      "Line data-output/stops-agg/108.json created (131)\n",
      "Line data-output/stops-agg/110.json created (100)\n",
      "Line data-output/stops-agg/111.json created (104)\n",
      "Line data-output/stops-agg/115.json created (121)\n",
      "Line data-output/stops-agg/117.json created (91)\n",
      "Line data-output/stops-agg/120.json created (127)\n",
      "Line data-output/stops-agg/125.json created (94)\n",
      "Line data-output/stops-agg/127.json created (52)\n",
      "Line data-output/stops-agg/128.json created (58)\n",
      "Line data-output/stops-agg/130.json created (100)\n",
      "Line data-output/stops-agg/150.json created (86)\n",
      "Line data-output/stops-agg/152.json created (102)\n",
      "Line data-output/stops-agg/154.json created (80)\n",
      "Line data-output/stops-agg/155.json created (71)\n",
      "Line data-output/stops-agg/158.json created (85)\n",
      "Line data-output/stops-agg/161.json created (82)\n",
      "Line data-output/stops-agg/162.json created (75)\n",
      "Line data-output/stops-agg/163.json created (73)\n",
      "Line data-output/stops-agg/164.json created (101)\n",
      "Line data-output/stops-agg/165.json created (103)\n",
      "Line data-output/stops-agg/166.json created (72)\n",
      "Line data-output/stops-agg/167.json created (112)\n",
      "Line data-output/stops-agg/169.json created (154)\n",
      "Line data-output/stops-agg/175.json created (36)\n",
      "Line data-output/stops-agg/176.json created (118)\n",
      "Line data-output/stops-agg/177.json created (0)\n",
      "Line data-output/stops-agg/180.json created (109)\n",
      "Line data-output/stops-agg/181.json created (125)\n",
      "Line data-output/stops-agg/183.json created (123)\n",
      "Line data-output/stops-agg/200.json created (44)\n",
      "Line data-output/stops-agg/201.json created (66)\n",
      "Line data-output/stops-agg/202.json created (74)\n",
      "Line data-output/stops-agg/204.json created (73)\n",
      "Line data-output/stops-agg/205.json created (143)\n",
      "Line data-output/stops-agg/206.json created (81)\n",
      "Line data-output/stops-agg/207.json created (68)\n",
      "Line data-output/stops-agg/209.json created (49)\n",
      "Line data-output/stops-agg/210.json created (100)\n",
      "Line data-output/stops-agg/211.json created (32)\n",
      "Line data-output/stops-agg/212.json created (87)\n",
      "Line data-output/stops-agg/215.json created (25)\n",
      "Line data-output/stops-agg/217.json created (61)\n",
      "Line data-output/stops-agg/218.json created (30)\n",
      "Line data-output/stops-agg/222.json created (86)\n",
      "Line data-output/stops-agg/224.json created (76)\n",
      "Line data-output/stops-agg/230.json created (55)\n",
      "Line data-output/stops-agg/232.json created (110)\n",
      "Line data-output/stops-agg/233.json created (72)\n",
      "Line data-output/stops-agg/234.json created (97)\n",
      "Line data-output/stops-agg/236.json created (67)\n",
      "Line data-output/stops-agg/237.json created (114)\n",
      "Line data-output/stops-agg/239.json created (77)\n",
      "Line data-output/stops-agg/240.json created (85)\n",
      "Line data-output/stops-agg/242.json created (32)\n",
      "Line data-output/stops-agg/243.json created (37)\n",
      "Line data-output/stops-agg/244.json created (30)\n",
      "Line data-output/stops-agg/245.json created (34)\n",
      "Line data-output/stops-agg/246.json created (77)\n",
      "Line data-output/stops-agg/251.json created (85)\n",
      "Line data-output/stops-agg/252.json created (36)\n",
      "Line data-output/stops-agg/256.json created (155)\n",
      "Line data-output/stops-agg/258.json created (96)\n",
      "Line data-output/stops-agg/260.json created (126)\n",
      "Line data-output/stops-agg/264.json created (73)\n",
      "Line data-output/stops-agg/265.json created (70)\n",
      "Line data-output/stops-agg/266.json created (91)\n",
      "Line data-output/stops-agg/267.json created (99)\n",
      "Line data-output/stops-agg/268.json created (104)\n",
      "Line data-output/stops-agg/344.json created (54)\n",
      "Line data-output/stops-agg/460.json created (98)\n",
      "Line data-output/stops-agg/487.json created (121)\n",
      "Line data-output/stops-agg/489.json created (46)\n",
      "Line data-output/stops-agg/501.json created (15)\n",
      "Line data-output/stops-agg/534.json created (48)\n",
      "Line data-output/stops-agg/550.json created (39)\n",
      "Line data-output/stops-agg/577.json created (9)\n",
      "Line data-output/stops-agg/601.json created (18)\n",
      "Line data-output/stops-agg/602.json created (68)\n",
      "Line data-output/stops-agg/603.json created (77)\n",
      "Line data-output/stops-agg/605.json created (33)\n",
      "Line data-output/stops-agg/611.json created (90)\n",
      "Line data-output/stops-agg/656.json created (79)\n",
      "Line data-output/stops-agg/665.json created (25)\n",
      "Line data-output/stops-agg/685.json created (37)\n",
      "Line data-output/stops-agg/686.json created (48)\n",
      "Line data-output/stops-agg/687.json created (47)\n",
      "Line data-output/stops-agg/704.json created (43)\n",
      "Line data-output/stops-agg/720.json created (48)\n",
      "Line data-output/stops-agg/733.json created (49)\n",
      "Line data-output/stops-agg/734.json created (35)\n",
      "Line data-output/stops-agg/744.json created (41)\n",
      "Line data-output/stops-agg/750.json created (23)\n",
      "Line data-output/stops-agg/754.json created (23)\n",
      "Line data-output/stops-agg/757.json created (25)\n",
      "Line data-output/stops-agg/770.json created (37)\n",
      "Line data-output/stops-agg/780.json created (37)\n",
      "Line data-output/stops-agg/788.json created (0)\n",
      "Line data-output/stops-agg/794.json created (39)\n",
      "Line data-output/stops-agg/901.json created (17)\n",
      "Line data-output/stops-agg/910.json created (32)\n",
      "Line data-output/stops-agg/950.json created (47)\n",
      "141 files created.\n"
     ]
    }
   ],
   "source": [
    "# Output the aggregated stop_ids to files by line \n",
    "\n",
    "line_regex = ''\n",
    "count = 0\n",
    "\n",
    "for line in lines_array:\n",
    "    line_regex = '^' + str(line) + '\\s'\n",
    "    line_filename = DATA_OUTPUT_PATH + 'stops-agg/' + str(line) + '.json'\n",
    "\n",
    "    # no de-dupping necessary because the data was already grouped by line + stop_name\n",
    "    stop_by_line = aggregated_grouped_stops[aggregated_grouped_stops.line == line]\n",
    "    stop_by_line = stop_by_line.rename(columns={'stop_id_agg':'stop_id'})\n",
    "    stop_by_line[['stop_id','stop_name']].sort_values('stop_name').to_json(line_filename, orient='records')\n",
    "\n",
    "    print('Line ' + line_filename + ' created' + ' (' + str(len(stop_by_line)) + ')')\n",
    "    count += 1\n",
    "\n",
    "print(str(count) + ' files created.')"
   ]
  },
  {
   "source": [
    "# Random Scratch Code Below"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# route_sn_column = lines.loc[:, 'route_short_name']\n",
    "# route_sn_array = route_sn_column.values\n",
    "# lines_adjusted = []\n",
    "\n",
    "# for i, line in enumerate(route_sn_array):\n",
    "#     slash = line.find('/')\n",
    "\n",
    "#     if slash > 0:\n",
    "#         lines_adjusted.append(line[:slash])\n",
    "#         lines_adjusted.append(line[slash+1:])\n",
    "#         continue\n",
    "#     else:\n",
    "#         lines_adjusted.append(line)\n",
    "\n",
    "# # 139 lines\n",
    "# print(lines_adjusted)\n",
    "# print('\\nTotal number of lines after split: ', len(lines_adjusted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# route_id_array = route_id_column.values\n",
    "# route_num_array = []\n",
    "\n",
    "# for i, line in enumerate(route_id_array):\n",
    "#     route_num_array.append('^' + route_id_array[i].replace('-13139','') + '\\s')\n",
    "\n",
    "# print(route_id_array)\n",
    "# print(route_num_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines_and_stops[lines_and_stops.stop_id == '3360']"
   ]
  }
 ]
}