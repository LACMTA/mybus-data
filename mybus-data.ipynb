{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Overview\n",
    "\n",
    "This Jupyter Notebook takes in GTFS data and then combines and adjusts the data in order to output these files:\n",
    "\n",
    "* `lines.json` - This file is a list of line numbers to be used in the MyBus tool (to select lines).\n",
    "* `[line-number].json` - A file for each line number that lists unique stops across all trips for that line.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "DATA_INPUT_PATH = 'data-input/'\n",
    "DATA_OUTPUT_PATH = 'data-output/'"
   ]
  },
  {
   "source": [
    "# Load GTFS Data\n",
    "\n",
    "## __`routes.txt`__\n",
    "\n",
    "GTFS files are pulled from: https://gitlab.com/LACMTA/gtfs_bus\n",
    "\n",
    "The data used here is from version hash `9a71d665`.\n",
    "\n",
    "* `route_id`\n",
    "* `route_short_name`\n",
    "\n",
    "## __`stops.txt`__\n",
    "\n",
    "* `stop_id`\n",
    "* `stop_name`\n",
    "* `stop_lat`\n",
    "* `stop_lng`\n",
    "\n",
    "## __`stop_times.txt`__\n",
    "\n",
    "* `trip_id`\n",
    "* `stop_id`\n",
    "* `stop_sequence`\n",
    "* `stop_headsign`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      route_id                  route_short_name\n",
       "119  854-13139                              <NA>\n",
       "120  901-13139                              <NA>\n",
       "121  910-13139                              <NA>\n",
       "122     DSE-HG  South Bay Dodger Stadium Express\n",
       "123     DSE-US            Dodger Stadium Express"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>route_id</th>\n      <th>route_short_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>119</th>\n      <td>854-13139</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>901-13139</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>910-13139</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>DSE-HG</td>\n      <td>South Bay Dodger Stadium Express</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>DSE-US</td>\n      <td>Dodger Stadium Express</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "lines = pd.read_csv(DATA_INPUT_PATH + 'routes.txt', \n",
    "    usecols={'route_id', 'route_short_name'},\n",
    "    dtype={'route_id':'string', 'route_short_name':'string'})\n",
    "\n",
    "lines.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  stop_id                            stop_name   stop_lat    stop_lon\n",
       "0       1                  Paramount / Slauson  33.973248 -118.113113\n",
       "1       3                     Jefferson / 10th  34.025471 -118.328402\n",
       "2       6           120th / Augustus F Hawkins  33.924696 -118.242222\n",
       "3       7  120th / Martin Luther King Hospital  33.924505 -118.240369\n",
       "4      12                    15054 Sherman Way  34.201075 -118.461953"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stop_id</th>\n      <th>stop_name</th>\n      <th>stop_lat</th>\n      <th>stop_lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Paramount / Slauson</td>\n      <td>33.973248</td>\n      <td>-118.113113</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Jefferson / 10th</td>\n      <td>34.025471</td>\n      <td>-118.328402</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>120th / Augustus F Hawkins</td>\n      <td>33.924696</td>\n      <td>-118.242222</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>120th / Martin Luther King Hospital</td>\n      <td>33.924505</td>\n      <td>-118.240369</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12</td>\n      <td>15054 Sherman Way</td>\n      <td>34.201075</td>\n      <td>-118.461953</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "stops = pd.read_csv(DATA_INPUT_PATH + 'stops.txt',\n",
    "    usecols=['stop_id','stop_name','stop_lat','stop_lon'],\n",
    "    dtype={'stop_id':'string','stop_name':'string','stop_lat':'float64','stop_lon':'float64'})\n",
    "stops.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                           trip_id stop_id  stop_sequence  \\\n",
       "0  52088401-DEC20-D02CAR-1_Weekday   10246              1   \n",
       "1  52088401-DEC20-D02CAR-1_Weekday   10248              2   \n",
       "2  52088401-DEC20-D02CAR-1_Weekday    9371              3   \n",
       "3  52088401-DEC20-D02CAR-1_Weekday    9350              4   \n",
       "4  52088401-DEC20-D02CAR-1_Weekday    9351              5   \n",
       "\n",
       "          stop_headsign  \n",
       "0  611 - Vernon Station  \n",
       "1  611 - Vernon Station  \n",
       "2  611 - Vernon Station  \n",
       "3  611 - Vernon Station  \n",
       "4  611 - Vernon Station  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trip_id</th>\n      <th>stop_id</th>\n      <th>stop_sequence</th>\n      <th>stop_headsign</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>10246</td>\n      <td>1</td>\n      <td>611 - Vernon Station</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>10248</td>\n      <td>2</td>\n      <td>611 - Vernon Station</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>9371</td>\n      <td>3</td>\n      <td>611 - Vernon Station</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>9350</td>\n      <td>4</td>\n      <td>611 - Vernon Station</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>9351</td>\n      <td>5</td>\n      <td>611 - Vernon Station</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "stop_times = pd.read_csv(DATA_INPUT_PATH + 'stop_times.txt',\n",
    "    usecols=['trip_id','stop_id','stop_sequence','stop_headsign'],\n",
    "    dtype={'trip_id':'string','stop_id':'string','stop_sequence':'int64','stop_headsign':'string'})\n",
    "stop_times.head(5)"
   ]
  },
  {
   "source": [
    "# Output Lines\n",
    "\n",
    "Output file as: `lines.json`.\n",
    "\n",
    "`.to_json()` method\n",
    "\n",
    "* Only works on a DataFrame\n",
    "* Outputs data by column - use `orient='records'` to output by record\n",
    "\n",
    "Fields in output:\n",
    "\n",
    "* `route_id` - route number plus HASTUS version. For lines with sister routes, will only list first line.\n",
    "  * Ex: `10-13139`\n",
    "* `route_short_name` - route number, includes sister routes.\n",
    "  * Ex: `10/48`\n",
    "\n",
    "Modifications:\n",
    "\n",
    "* The Silver Line and Orange Line do not have `route_short_name` values so those have to be manually added.\n",
    "* The L Line Shuttle and the two Dodger Stadium Express Shuttles will be removed since they're temporary services.\n",
    "* Lines with sister routes may need to be separated to treat each as separate lines.  Unless... a rider can stay on a single vehicle and end up on the other line.  In that case we would want to combine the stops for both lines so they are selectable from the landing page.\n",
    "\n",
    "## MyBus Usage\n",
    "\n",
    "Landing Page - Line Select Dropdown\n",
    "\n",
    "* `route_id` - use as button value, pass this to the results page as a URL parameter\n",
    "* `route_short_name` - user-friendly text for the dropdown (just a number)\n",
    "\n",
    "Results Page - Header\n",
    "\n",
    "* `route_short_name` - use as H1\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      route_id  route_short_name\n",
       "103  780-13139               780\n",
       "104  794-13139               794\n",
       "105  901-13139               901\n",
       "134  910-13139               910\n",
       "135  910-13139               950"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>route_id</th>\n      <th>route_short_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>103</th>\n      <td>780-13139</td>\n      <td>780</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>794-13139</td>\n      <td>794</td>\n    </tr>\n    <tr>\n      <th>105</th>\n      <td>901-13139</td>\n      <td>901</td>\n    </tr>\n    <tr>\n      <th>134</th>\n      <td>910-13139</td>\n      <td>910</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>910-13139</td>\n      <td>950</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Add route_short_name values for the 901 (Orange Line) and 910/950 (Silver Line)\n",
    "lines.loc[lines[\"route_id\"] == '910-13139', 'route_short_name'] = '910/950'\n",
    "lines.loc[lines[\"route_id\"] == '901-13139', 'route_short_name'] = '901'\n",
    "\n",
    "# Remove the entries for the Dodger Express and L Line (Gold) Shuttle\n",
    "lines = lines.loc[~lines[\"route_id\"].isin(['DSE-HG'])]\n",
    "lines = lines.loc[~lines[\"route_id\"].isin(['DSE-US'])]\n",
    "lines = lines.loc[~lines[\"route_id\"].isin(['854-13139'])]\n",
    "\n",
    "# Separate out the sister lines.\n",
    "lines_array = lines.loc[lines['route_short_name'].str.contains('/'), 'route_short_name'].values\n",
    "\n",
    "for i, l in enumerate(lines_array):\n",
    "    id = lines.loc[lines['route_short_name'] == l]['route_id'].values[0]\n",
    "    slash = l.find('/')\n",
    "    line1 = l[:slash]\n",
    "    line2 = l[slash+1:]\n",
    "    \n",
    "    lines = lines.loc[~lines[\"route_id\"].isin([id])]\n",
    "    newlines = pd.DataFrame([[id, line1], [id, line2]], columns=['route_id', 'route_short_name'])\n",
    "    lines = lines.append(newlines, ignore_index=True)\n",
    "\n",
    "# cast route_short_name to int32 so that we can sort by their integer value\n",
    "lines = lines.astype({'route_short_name': 'int32'}).sort_values('route_short_name')\n",
    "lines.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     route_id  route_short_name\n",
       "0     2-13139                 2\n",
       "1     4-13139                 4\n",
       "106  10-13139                10\n",
       "108  14-13139                14\n",
       "2    16-13139                16"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>route_id</th>\n      <th>route_short_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2-13139</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4-13139</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>10-13139</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>14-13139</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16-13139</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "# Output the LINES dataframe to a JSON file\n",
    "lines.to_json(DATA_OUTPUT_PATH + \"lines.json\",orient='records')\n",
    "lines.head(5)"
   ]
  },
  {
   "source": [
    "# Combine Stops Data\n",
    "\n",
    "Merge `stop_times` and `stops` using a LEFT JOIN on `stop_id`.  For each stop on a line, this will show that stop's name and lat/lng.\n",
    "\n",
    "Use the `lines_and_stops` dataframe to generate a file for each line that lists all unique stops for that line."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                           trip_id stop_id  stop_sequence  \\\n",
       "0  52088401-DEC20-D02CAR-1_Weekday   10246              1   \n",
       "1  52088401-DEC20-D02CAR-1_Weekday   10248              2   \n",
       "2  52088401-DEC20-D02CAR-1_Weekday    9371              3   \n",
       "3  52088401-DEC20-D02CAR-1_Weekday    9350              4   \n",
       "4  52088401-DEC20-D02CAR-1_Weekday    9351              5   \n",
       "\n",
       "          stop_headsign            stop_name   stop_lat    stop_lon  \n",
       "0  611 - Vernon Station  Vernon / Long Beach  34.004050 -118.242837  \n",
       "1  611 - Vernon Station      Vernon / Morgan  34.004040 -118.244926  \n",
       "2  611 - Vernon Station     Compton / Vernon  34.003630 -118.247907  \n",
       "3  611 - Vernon Station       Compton / 46th  34.001767 -118.247915  \n",
       "4  611 - Vernon Station       Compton / 48th  33.999487 -118.247918  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trip_id</th>\n      <th>stop_id</th>\n      <th>stop_sequence</th>\n      <th>stop_headsign</th>\n      <th>stop_name</th>\n      <th>stop_lat</th>\n      <th>stop_lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>10246</td>\n      <td>1</td>\n      <td>611 - Vernon Station</td>\n      <td>Vernon / Long Beach</td>\n      <td>34.004050</td>\n      <td>-118.242837</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>10248</td>\n      <td>2</td>\n      <td>611 - Vernon Station</td>\n      <td>Vernon / Morgan</td>\n      <td>34.004040</td>\n      <td>-118.244926</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>9371</td>\n      <td>3</td>\n      <td>611 - Vernon Station</td>\n      <td>Compton / Vernon</td>\n      <td>34.003630</td>\n      <td>-118.247907</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>9350</td>\n      <td>4</td>\n      <td>611 - Vernon Station</td>\n      <td>Compton / 46th</td>\n      <td>34.001767</td>\n      <td>-118.247915</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>52088401-DEC20-D02CAR-1_Weekday</td>\n      <td>9351</td>\n      <td>5</td>\n      <td>611 - Vernon Station</td>\n      <td>Compton / 48th</td>\n      <td>33.999487</td>\n      <td>-118.247918</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "lines_and_stops = pd.merge(stop_times, stops, how=\"left\", on=\"stop_id\")\n",
    "lines_and_stops.head(5)\n",
    "\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^48\\s', regex=True)]\n"
   ]
  },
  {
   "source": [
    "# Looking at Stops Data\n",
    "\n",
    "Questions:\n",
    "\n",
    "* How many records are there in `lines_and_stops` for a particular line?\n",
    "  * Use REGEX matching on `stop_headsign`. Will need to use an OR operator for sisters lines because each has distinct headsign values.\n",
    "* Of those records, how many unique `trip_id`s are there?\n",
    "* Of those records, how many unique `stop_name`s are there?\n",
    "* What is the highest `stop_sequence` value for that line?\n",
    "\n",
    "## Stops Data Findings\n",
    "\n",
    "Line 2\n",
    "\n",
    "* 31,094 stop times along Line 2\n",
    "* 377 unique trips\n",
    "* 92 stops MAX within a single trip\n",
    "* 377 x 92 = 34,684 - this means there are some trips with fewer than 92 stops\n",
    "* 123 unique stop names - this means trips do not all contain the same set of stops\n",
    "\n",
    "Line 10/48\n",
    "\n",
    "* ??\n",
    "\n",
    "Highest `stop_sequence`\n",
    "\n",
    "* Line 90\n",
    "* 136 is the highest value\n",
    "* Line 90 has 158 total unique stops."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################\n",
    "#  Line 2          #\n",
    "####################\n",
    "\n",
    "# All values for Line 2 = 31,094\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^2\\s', regex=True)]\n",
    " \n",
    "# Unique stop names for Line 2 = 123\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^2\\s', regex=True)].stop_name.unique()\n",
    "\n",
    "# Unique trip_ids for Line 2 = 377\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^2\\s', regex=True)].trip_id.unique()\n",
    "\n",
    "# Line 2 stops sorted by highest stop_sequence value = 92\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^2\\s', regex=True)].sort_values('stop_sequence', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "#  Lines 10/48     #\n",
    "####################\n",
    "\n",
    "# REGEX: ^(10\\s|48\\s)\n",
    "\n",
    "# All values for Line 10 = 12,534 rows\n",
    "# All values for Line 10/48 = 16,524 rows\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^10\\s', regex=True)]\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^(10\\s|48\\s)', regex=True)]\n",
    "\n",
    "# Unique trip_ids for Line 10 = 231\n",
    "# Unique trip_ids for Line 10/48 = 316\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^10\\s', regex=True)].trip_id.unique()\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^(10\\s|48\\s)', regex=True)].trip_id.unique()\n",
    "\n",
    "# Unique stop names for Line 10 = 117\n",
    "# Unique stop names for Line 10/48 = 132\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^10\\s', regex=True)].stop_name.unique()\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^(10\\s|48\\s)', regex=True)].stop_name.unique()\n",
    "\n",
    "# Line 10/48 stops sorted by highest stop_sequence value = 102\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^(10\\s|48\\s)', regex=True)].sort_values('stop_sequence', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line 90 has highest stop_sequence value of 136\n",
    "#lines_and_stops.sort_values('stop_sequence', ascending=False).head(10)\n",
    "\n",
    "# Line 90 has 158 unique stop names\n",
    "#lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^90\\s', regex=True)].stop_name.unique()"
   ]
  },
  {
   "source": [
    "# Output All Unique Stops for Line 2\n",
    "\n",
    "File output as `2-13139.json`\n",
    "\n",
    "Use `.drop_duplicates()` to generate a new dataframe with only unique values.  Using `.[column name].unique()` outputs a StringArray and we need a DataFrame in order to call `.to_json()`.\n",
    "\n",
    "Sort results by `stop_name` because we're combining multiple trips that may each have their own set of stops along their routes.\n",
    "\n",
    "Fields in output:\n",
    "\n",
    "* `stop_id`\n",
    "* `stop_name`\n",
    "\n",
    "## Usage\n",
    "\n",
    "Landing Page - Stop Select Dropdowns\n",
    "\n",
    "* `stop_id` - use as button value, pass this to the results page as a URL parameter\n",
    "* `stop_name` - user-friendly text for the dropdown\n",
    "\n",
    "## TODO\n",
    "\n",
    "* Check `stop_name`s for any abbreviations that should be corrected."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                trip_id stop_id  stop_sequence  \\\n",
       "846104  52248752-DEC20-D18CAR-1_Weekday  141012              1   \n",
       "846105  52248752-DEC20-D18CAR-1_Weekday    5397              2   \n",
       "846106  52248752-DEC20-D18CAR-1_Weekday    5396              3   \n",
       "846107  52248752-DEC20-D18CAR-1_Weekday    5395              4   \n",
       "846108  52248752-DEC20-D18CAR-1_Weekday    5410              5   \n",
       "\n",
       "                                        stop_headsign               stop_name  \\\n",
       "846104  950 - Silver Line - El Monte Sta Via Downtown  Pacific / 21st Layover   \n",
       "846105  950 - Silver Line - El Monte Sta Via Downtown          Pacific / 17th   \n",
       "846106  950 - Silver Line - El Monte Sta Via Downtown          Pacific / 15th   \n",
       "846107  950 - Silver Line - El Monte Sta Via Downtown          Pacific / 11th   \n",
       "846108  950 - Silver Line - El Monte Sta Via Downtown           Pacific / 7th   \n",
       "\n",
       "         stop_lat    stop_lon  \n",
       "846104  33.724933 -118.288128  \n",
       "846105  33.728654 -118.287802  \n",
       "846106  33.730465 -118.287791  \n",
       "846107  33.734092 -118.287774  \n",
       "846108  33.737728 -118.287757  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trip_id</th>\n      <th>stop_id</th>\n      <th>stop_sequence</th>\n      <th>stop_headsign</th>\n      <th>stop_name</th>\n      <th>stop_lat</th>\n      <th>stop_lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>846104</th>\n      <td>52248752-DEC20-D18CAR-1_Weekday</td>\n      <td>141012</td>\n      <td>1</td>\n      <td>950 - Silver Line - El Monte Sta Via Downtown</td>\n      <td>Pacific / 21st Layover</td>\n      <td>33.724933</td>\n      <td>-118.288128</td>\n    </tr>\n    <tr>\n      <th>846105</th>\n      <td>52248752-DEC20-D18CAR-1_Weekday</td>\n      <td>5397</td>\n      <td>2</td>\n      <td>950 - Silver Line - El Monte Sta Via Downtown</td>\n      <td>Pacific / 17th</td>\n      <td>33.728654</td>\n      <td>-118.287802</td>\n    </tr>\n    <tr>\n      <th>846106</th>\n      <td>52248752-DEC20-D18CAR-1_Weekday</td>\n      <td>5396</td>\n      <td>3</td>\n      <td>950 - Silver Line - El Monte Sta Via Downtown</td>\n      <td>Pacific / 15th</td>\n      <td>33.730465</td>\n      <td>-118.287791</td>\n    </tr>\n    <tr>\n      <th>846107</th>\n      <td>52248752-DEC20-D18CAR-1_Weekday</td>\n      <td>5395</td>\n      <td>4</td>\n      <td>950 - Silver Line - El Monte Sta Via Downtown</td>\n      <td>Pacific / 11th</td>\n      <td>33.734092</td>\n      <td>-118.287774</td>\n    </tr>\n    <tr>\n      <th>846108</th>\n      <td>52248752-DEC20-D18CAR-1_Weekday</td>\n      <td>5410</td>\n      <td>5</td>\n      <td>950 - Silver Line - El Monte Sta Via Downtown</td>\n      <td>Pacific / 7th</td>\n      <td>33.737728</td>\n      <td>-118.287757</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "source": [
    "# ONLY FOR LINE 2\n",
    "\n",
    "# Creete a dataframe dropping duplicate stop names\n",
    "#dedupped_stops = lines_and_stops[lines_and_stops['stop_headsign'].str.contains('^2\\s', regex=True)].drop_duplicates(subset='stop_name')\n",
    "\n",
    "#dedupped_stops[['stop_id','stop_name']].sort_values('stop_name').to_json(DATA_OUTPUT_PATH + '2-13139.json', orient='records')\n",
    "\n",
    "#dedupped_stops.head()"
   ]
  },
  {
   "source": [
    "# Output All Stops For Each Line\n",
    "\n",
    "Loop through data to generate a separate file for each line.  Each file will contain all unique `stop_name`s for that line.  Lines are matched using the `stop_headsign` field.  Only one line number shows up at a time in the `stop_headsign`.\n",
    "\n",
    "## Method\n",
    "\n",
    "* Create an array of all the `route_short_name` values which should match the line numbers within `stop_headsign`.\n",
    "* For each of those line numbers, find the rows in `lines_and_stops` that contain that line number within `stop_headsign`.\n",
    "* From those values, drop duplicate `stop_name`s to create a list of all unique stops for that line.\n",
    "* Sort the values so the `stop_name`s are in alphabetical order and output the results to JSON files.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Line data-output/2.json created\n",
      "Line data-output/4.json created\n",
      "Line data-output/10.json created\n",
      "Line data-output/14.json created\n",
      "Line data-output/16.json created\n",
      "Line data-output/18.json created\n",
      "Line data-output/20.json created\n",
      "Line data-output/28.json created\n",
      "Line data-output/30.json created\n",
      "Line data-output/33.json created\n",
      "Line data-output/35.json created\n",
      "Line data-output/37.json created\n",
      "Line data-output/38.json created\n",
      "Line data-output/40.json created\n",
      "Line data-output/45.json created\n",
      "Line data-output/48.json created\n",
      "Line data-output/51.json created\n",
      "Line data-output/52.json created\n",
      "Line data-output/53.json created\n",
      "Line data-output/55.json created\n",
      "Line data-output/60.json created\n",
      "Line data-output/62.json created\n",
      "Line data-output/66.json created\n",
      "Line data-output/68.json created\n",
      "Line data-output/70.json created\n",
      "Line data-output/71.json created\n",
      "Line data-output/76.json created\n",
      "Line data-output/78.json created\n",
      "Line data-output/79.json created\n",
      "Line data-output/81.json created\n",
      "Line data-output/83.json created\n",
      "Line data-output/90.json created\n",
      "Line data-output/91.json created\n",
      "Line data-output/92.json created\n",
      "Line data-output/94.json created\n",
      "Line data-output/96.json created\n",
      "Line data-output/102.json created\n",
      "Line data-output/105.json created\n",
      "Line data-output/106.json created\n",
      "Line data-output/108.json created\n",
      "Line data-output/110.json created\n",
      "Line data-output/111.json created\n",
      "Line data-output/115.json created\n",
      "Line data-output/117.json created\n",
      "Line data-output/120.json created\n",
      "Line data-output/125.json created\n",
      "Line data-output/127.json created\n",
      "Line data-output/128.json created\n",
      "Line data-output/130.json created\n",
      "Line data-output/150.json created\n",
      "Line data-output/152.json created\n",
      "Line data-output/154.json created\n",
      "Line data-output/155.json created\n",
      "Line data-output/158.json created\n",
      "Line data-output/161.json created\n",
      "Line data-output/162.json created\n",
      "Line data-output/163.json created\n",
      "Line data-output/164.json created\n",
      "Line data-output/165.json created\n",
      "Line data-output/166.json created\n",
      "Line data-output/167.json created\n",
      "Line data-output/169.json created\n",
      "Line data-output/175.json created\n",
      "Line data-output/176.json created\n",
      "Line data-output/180.json created\n",
      "Line data-output/181.json created\n",
      "Line data-output/183.json created\n",
      "Line data-output/200.json created\n",
      "Line data-output/201.json created\n",
      "Line data-output/202.json created\n",
      "Line data-output/204.json created\n",
      "Line data-output/205.json created\n",
      "Line data-output/206.json created\n",
      "Line data-output/207.json created\n",
      "Line data-output/209.json created\n",
      "Line data-output/210.json created\n",
      "Line data-output/211.json created\n",
      "Line data-output/212.json created\n",
      "Line data-output/215.json created\n",
      "Line data-output/217.json created\n",
      "Line data-output/218.json created\n",
      "Line data-output/222.json created\n",
      "Line data-output/224.json created\n",
      "Line data-output/230.json created\n",
      "Line data-output/232.json created\n",
      "Line data-output/233.json created\n",
      "Line data-output/234.json created\n",
      "Line data-output/236.json created\n",
      "Line data-output/237.json created\n",
      "Line data-output/239.json created\n",
      "Line data-output/240.json created\n",
      "Line data-output/242.json created\n",
      "Line data-output/243.json created\n",
      "Line data-output/245.json created\n",
      "Line data-output/246.json created\n",
      "Line data-output/251.json created\n",
      "Line data-output/252.json created\n",
      "Line data-output/256.json created\n",
      "Line data-output/258.json created\n",
      "Line data-output/260.json created\n",
      "Line data-output/264.json created\n",
      "Line data-output/265.json created\n",
      "Line data-output/266.json created\n",
      "Line data-output/267.json created\n",
      "Line data-output/268.json created\n",
      "Line data-output/344.json created\n",
      "Line data-output/460.json created\n",
      "Line data-output/487.json created\n",
      "Line data-output/501.json created\n",
      "Line data-output/534.json created\n",
      "Line data-output/550.json created\n",
      "Line data-output/577.json created\n",
      "Line data-output/601.json created\n",
      "Line data-output/602.json created\n",
      "Line data-output/603.json created\n",
      "Line data-output/605.json created\n",
      "Line data-output/611.json created\n",
      "Line data-output/656.json created\n",
      "Line data-output/665.json created\n",
      "Line data-output/685.json created\n",
      "Line data-output/686.json created\n",
      "Line data-output/687.json created\n",
      "Line data-output/704.json created\n",
      "Line data-output/720.json created\n",
      "Line data-output/733.json created\n",
      "Line data-output/734.json created\n",
      "Line data-output/744.json created\n",
      "Line data-output/750.json created\n",
      "Line data-output/754.json created\n",
      "Line data-output/757.json created\n",
      "Line data-output/770.json created\n",
      "Line data-output/780.json created\n",
      "Line data-output/794.json created\n",
      "Line data-output/901.json created\n",
      "Line data-output/910.json created\n",
      "Line data-output/950.json created\n"
     ]
    }
   ],
   "source": [
    "lines_array = lines.loc[:, 'route_short_name'].values\n",
    "line_regex = ''\n",
    "\n",
    "for line in lines_array:\n",
    "    line_regex = '^' + str(line) + '\\s'\n",
    "    line_filename = DATA_OUTPUT_PATH + str(line) + '.json'\n",
    "\n",
    "    dedupped_stops = lines_and_stops[lines_and_stops['stop_headsign'].str.contains(line_regex, regex=True)].drop_duplicates(subset='stop_name')\n",
    "    dedupped_stops[['stop_id','stop_name']].sort_values('stop_name').to_json(line_filename, orient='records')\n",
    "\n",
    "    print('Line ' + line_filename + ' created')"
   ]
  },
  {
   "source": [
    "# Random Scratch Code Below"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# route_sn_column = lines.loc[:, 'route_short_name']\n",
    "# route_sn_array = route_sn_column.values\n",
    "# lines_adjusted = []\n",
    "\n",
    "# for i, line in enumerate(route_sn_array):\n",
    "#     slash = line.find('/')\n",
    "\n",
    "#     if slash > 0:\n",
    "#         lines_adjusted.append(line[:slash])\n",
    "#         lines_adjusted.append(line[slash+1:])\n",
    "#         continue\n",
    "#     else:\n",
    "#         lines_adjusted.append(line)\n",
    "\n",
    "# # 139 lines\n",
    "# print(lines_adjusted)\n",
    "# print('\\nTotal number of lines after split: ', len(lines_adjusted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# route_id_array = route_id_column.values\n",
    "# route_num_array = []\n",
    "\n",
    "# for i, line in enumerate(route_id_array):\n",
    "#     route_num_array.append('^' + route_id_array[i].replace('-13139','') + '\\s')\n",
    "\n",
    "# print(route_id_array)\n",
    "# print(route_num_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}